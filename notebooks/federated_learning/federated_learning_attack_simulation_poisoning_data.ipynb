{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Federated learning: attack simulation\n",
    "\n",
    "In this notebook, we provide a simulation of a simple federated data poisoning attack. First, we will use a simple  approach that consists of shuffling the training labels of some clients, which will become adversarial.\n",
    "\n",
    "This notebook presents the class `FederatedDataAttack` in [federated_attack.py](https://github.com/sherpaai/Sherpa.ai-Federated-Learning-Framework/blob/master/shfl/private/federated_attack.py), whose goal is to implement any attack on the federated data. \n",
    "For more information about basic federated learning concepts, please refer to the notebook [Federated learning basic concepts](./federated_learning_basic_concepts.ipynb).\n",
    "\n",
    "For this simulation, we use the [Emnist](https://www.nist.gov/itl/products-and-services/emnist-dataset) digits dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from shfl.data_base import Emnist\n",
    "from shfl.data_distribution import NonIidDataDistribution\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "\n",
    "database = Emnist()\n",
    "train_data, train_labels, test_data, test_labels = database.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we distribute the data among the client nodes using a non-IID distribution over 10% of the data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "noniid_distribution = NonIidDataDistribution(database)\n",
    "nodes_federation, test_data, test_labels = noniid_distribution.get_nodes_federation(num_nodes=20, percent=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point, we are ready to apply a data attack to some nodes. \n",
    "For this simulation, we choose to apply data poisoning to the 20% of the nodes. \n",
    "To do so, we use the class `FederatedPoisoningDataAttack`, which simulates data poisoning in a certain percentage of the nodes. \n",
    "\n",
    "We create a `FederatedPoisoningDataAttack` object with the percentage set to 20% and apply the attack over `nodes_federation`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from shfl.private.federated_attack import FederatedPoisoningDataAttack\n",
    "\n",
    "random.seed(123)\n",
    "simple_attack = FederatedPoisoningDataAttack(percentage=20)\n",
    "simple_attack(nodes_federation = nodes_federation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can get the adversarial nodes in order to show the applied attack."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "adversarial_nodes = simple_attack.adversaries\n",
    "adversarial_nodes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to show the effect of the attack, we select one adversarial client and an index position and show the data and the label associated with this image. \n",
    "We change data access protection (see [NodesFederation](https://github.com/sherpaai/Sherpa.ai-Federated-Learning-Framework/blob/master/shfl/private/federated_operation.py)), in order to access the data. \n",
    "Due to the nature of the data poisoning (random shuffle), it is possible that for some specific data, the label will match, but in most cases it will not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from shfl.private.utils import unprotected_query\n",
    "\n",
    "adversarial_index = 0\n",
    "data_index = 10\n",
    "\n",
    "nodes_federation.configure_data_access(unprotected_query);\n",
    "\n",
    "plt.imshow(nodes_federation[adversarial_nodes[adversarial_index]].query().data[data_index])\n",
    "print(nodes_federation[adversarial_index].query().label[data_index])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point, we can train a FL model among these clients (adversarial and regular) using a specific aggregation operator. For more information, please see the [A Simple Experiment](./federated_learning_basic_concepts.ipynb) notebook."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SherpaFL_py37",
   "language": "python",
   "name": "sherpafl_py37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
